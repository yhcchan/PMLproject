<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Pmlproject by yhcchan</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Pmlproject</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/yhcchan/PMLproject" class="btn">View on GitHub</a>
      <a href="https://github.com/yhcchan/PMLproject/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/yhcchan/PMLproject/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p></p>PML Course Project 1



<p>
</p>







code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }




<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}


<div>


<div id="header">
<h1>
<a id="pml-course-project-1" class="anchor" href="#pml-course-project-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>PML Course Project 1</h1>
</div>

<div id="practical-machine-learning-course-project">
<h3>
<a id="practical-machine-learning-course-project" class="anchor" href="#practical-machine-learning-course-project" aria-hidden="true"><span class="octicon octicon-link"></span></a>Practical Machine Learning Course Project</h3>
</div>

<div id="overview">
<h2>
<a id="overview" class="anchor" href="#overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overview</h2>
<p>In this project, I construct and fit a model for the HAR dataset that predicts the manner in which participants in a Human Activity Recognition (HAR) study perform various weightlifting exercises from the available data.</p>
<p>I first conduct exploratory data analysis to isolate variables for inclusion into the model. Then, I split the training set into training and validation subsets, and perform cross-validation on the training subset to minimise out-of-sample errors. I then test the model against the validation dataset, then finally against the test dataset (with 20 variables) that has been divided.</p>
</div>

<div id="loading-in-data">
<h2>
<a id="loading-in-data" class="anchor" href="#loading-in-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading in Data</h2>
<pre><code>library(caret)</code></pre>
<pre><code>## Warning: package 'caret' was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: lattice
## Loading required package: ggplot2</code></pre>
<pre><code>## Warning: package 'ggplot2' was built under R version 3.1.3</code></pre>
<pre><code>rawtrain &lt;- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!"))
testing &lt;- read.csv("pml-testing.csv", na.strings = c("NA", "#DIV/0!"))</code></pre>
</div>

<div id="exploratory-data-analysis-and-processing">
<h2>
<a id="exploratory-data-analysis-and-processing" class="anchor" href="#exploratory-data-analysis-and-processing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exploratory Data Analysis and Processing</h2>
<p>Before we begin constructing the data, we perform some rudimentary exploratory data analysis and data processing in order to select the relevant predictors on which to build our base model. We first have a look at the dataset:</p>
<pre><code>head(rawtrain[,c(1:10, 15:20)])</code></pre>
<pre><code>##   X user_name raw_timestamp_part_1 raw_timestamp_part_2   cvtd_timestamp
## 1 1  carlitos           1323084231               788290 05/12/2011 11:23
## 2 2  carlitos           1323084231               808298 05/12/2011 11:23
## 3 3  carlitos           1323084231               820366 05/12/2011 11:23
## 4 4  carlitos           1323084232               120339 05/12/2011 11:23
## 5 5  carlitos           1323084232               196328 05/12/2011 11:23
## 6 6  carlitos           1323084232               304277 05/12/2011 11:23
##   new_window num_window roll_belt pitch_belt yaw_belt skewness_roll_belt
## 1         no         11      1.41       8.07    -94.4                 NA
## 2         no         11      1.41       8.07    -94.4                 NA
## 3         no         11      1.42       8.07    -94.4                 NA
## 4         no         12      1.48       8.05    -94.4                 NA
## 5         no         12      1.48       8.07    -94.4                 NA
## 6         no         12      1.45       8.06    -94.4                 NA
##   skewness_roll_belt.1 skewness_yaw_belt max_roll_belt max_picth_belt
## 1                   NA                NA            NA             NA
## 2                   NA                NA            NA             NA
## 3                   NA                NA            NA             NA
## 4                   NA                NA            NA             NA
## 5                   NA                NA            NA             NA
## 6                   NA                NA            NA             NA
##   max_yaw_belt
## 1           NA
## 2           NA
## 3           NA
## 4           NA
## 5           NA
## 6           NA</code></pre>
<p>From a cursory look at a truncated version of the dataset, we can see that there are a number of summary variables and classification variables which will not be relevant to our analysis. There are also a large number of variables without much meaningful data (i.e. the variables with large numbers of NA variables).</p>
<p>Using the existince of an NA value in the first row of the dataset as a classifying heuristic, we eliminate these summary variables, as well as variables that have insufficient entries for meaningful analysis:</p>
<pre><code>ss &lt;- rawtrain[, -c(1:7)]
subset &lt;- ss[which(!is.na(ss[1,]))]
col &lt;- colnames(subset)</code></pre>
<p>We are now ready to construct a model for this data.</p>
</div>

<div id="constructing-the-model">
<h2>
<a id="constructing-the-model" class="anchor" href="#constructing-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Constructing the Model</h2>
<p>As the testing sample given does not have classe variables, we must first split our current dataset further into training and validation subsets in order to obtain the out-of-sample error estimates later:</p>
<pre><code>inTrain &lt;- createDataPartition(y=subset$classe, p = 0.7, list = FALSE)
subtraining &lt;- subset[inTrain,]
subvalidation &lt;- subset[-inTrain,]</code></pre>
<p>With the data separated, we then train the model as follows, using the Random Forest method. Other algorithms common for modeling on categorical variables as outcomes were attempted, such as rpart, with poor accuracy. As such, we stuck to the RF method, which promised greatest accuracy, but at cost to speed and interpretability. We also set parameters for cross-validation of the training data:</p>
<pre><code>tc &lt;- trainControl(method = "cv", number = 6)
modelFit &lt;- train(classe~., trControl = tc, data = subtraining, method = "rf")</code></pre>
<pre><code>## Loading required package: randomForest
## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>modelFit</code></pre>
<pre><code>## Random Forest 
## 
## 13737 samples
##    52 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (6 fold) 
## Summary of sample sizes: 11447, 11448, 11447, 11448, 11447, 11448, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
##    2    0.9909004  0.9884880  0.001690514  0.002138594
##   27    0.9910461  0.9886730  0.001130087  0.001430300
##   52    0.9874065  0.9840688  0.002413288  0.003053327
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 27.</code></pre>
<p>From the summary of the fitted model above, we see that the optimal model is the one that uses 27 predictors, or mtry = 27. All other models attempted did not perform better than random selection in terms of predictive power. 5-fold cross validation was also used explicitly to minimise overfitting on the test dataset.</p>
</div>

<div id="fitting-model-to-validation-data-and-out-of-sample-error">
<h2>
<a id="fitting-model-to-validation-data-and-out-of-sample-error" class="anchor" href="#fitting-model-to-validation-data-and-out-of-sample-error" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fitting Model to Validation Data and Out-of-Sample Error</h2>
<p>We then proceed to fit the model derived above to the validation data in order to test the predictive power of our mode, as well as to get some sort of estimate of the out-of-sample error:</p>
<pre><code>prediction &lt;- predict(modelFit, subvalidation)</code></pre>
<pre><code>## Loading required package: randomForest
## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>confusionMatrix(prediction, subvalidation$classe)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1674    5    0    0    0
##          B    0 1134    2    0    0
##          C    0    0 1021    2    0
##          D    0    0    3  962    3
##          E    0    0    0    0 1079
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9975          
##                  95% CI : (0.9958, 0.9986)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9968          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9956   0.9951   0.9979   0.9972
## Specificity            0.9988   0.9996   0.9996   0.9988   1.0000
## Pos Pred Value         0.9970   0.9982   0.9980   0.9938   1.0000
## Neg Pred Value         1.0000   0.9989   0.9990   0.9996   0.9994
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2845   0.1927   0.1735   0.1635   0.1833
## Detection Prevalence   0.2853   0.1930   0.1738   0.1645   0.1833
## Balanced Accuracy      0.9994   0.9976   0.9974   0.9984   0.9986</code></pre>
<p>As can be seen, the accuracy, at 0.9975 on the validation set, is well within any reasonable standard of fit.</p>
<p>Finally, we derive the out-of-sample error of our validation sets, which was created through our cross-validation process. As the outcome is categorical, we can use missclassification error rates as our measure for out-of-sample error.</p>
<pre><code>error.oosample &lt;- sum(prediction != subvalidation$classe)/length(subvalidation$classe)
error.oosample</code></pre>
<pre><code>## [1] 0.002548853</code></pre>
<p>As such, the out-of-sample error is 0.0078 or about 0.78%.</p>
</div>

<div id="submission-script">
<h2>
<a id="submission-script" class="anchor" href="#submission-script" aria-hidden="true"><span class="octicon octicon-link"></span></a>Submission Script</h2>
<pre><code>pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}</code></pre>
</div>

<p></p>
</div>







<p>
</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/yhcchan/PMLproject">Pmlproject</a> is maintained by <a href="https://github.com/yhcchan">yhcchan</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
